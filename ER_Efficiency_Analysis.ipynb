{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meridian City Hospital - East ER Efficiency Analysis\n",
    "\n",
    "**Comprehensive Analysis for ER Datathon**\n",
    "\n",
    "This notebook performs a complete end-to-end analysis of the Emergency Room efficiency at Meridian City Hospital's East Location. The analysis includes:\n",
    "\n",
    "1. Data Loading & Cleaning\n",
    "2. Feature Engineering\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Machine Learning Models (Wait Time, Satisfaction, 15-min Target, Disposition)\n",
    "5. Statistical Correlations\n",
    "6. Scenario Simulations\n",
    "7. Executive Summary & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Visualization settings\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create outputs directory\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(\"✓ Outputs directory ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Loading all required CSV datasets for the East ER Location analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "patients_df = pd.read_csv('data/Hospital_Patients.csv')\n",
    "visits_df = pd.read_csv('data/Hospital_Visits.csv')\n",
    "staffing_df = pd.read_csv('data/Hospital_Staffing_EAST_LOCATION.csv')\n",
    "facility_df = pd.read_csv('data/Hospital_Facility.csv')\n",
    "outcomes_df = pd.read_csv('data/Hospital_Outcomes.csv')\n",
    "\n",
    "# Print dataset summaries\n",
    "print(\"Dataset Record Counts:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Patients: {len(patients_df):,} records\")\n",
    "print(f\"Visits: {len(visits_df):,} records\")\n",
    "print(f\"Staffing: {len(staffing_df):,} records\")\n",
    "print(f\"Facility: {len(facility_df):,} records\")\n",
    "print(f\"Outcomes: {len(outcomes_df):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data from each dataset\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PATIENTS DATASET (Sample)\")\n",
    "print(\"=\" * 50)\n",
    "display(patients_df.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"VISITS DATASET (Sample)\")\n",
    "print(\"=\" * 50)\n",
    "display(visits_df.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STAFFING DATASET (Sample)\")\n",
    "print(\"=\" * 50)\n",
    "display(staffing_df.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FACILITY DATASET (Sample)\")\n",
    "print(\"=\" * 50)\n",
    "display(facility_df.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"OUTCOMES DATASET (Sample)\")\n",
    "print(\"=\" * 50)\n",
    "display(outcomes_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Preprocessing\n",
    "\n",
    "Cleaning and standardizing all datasets before analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_flexible_date(date_str):\n",
    "    \"\"\"\n",
    "    Robust date parser that handles multiple timestamp formats.\n",
    "    \n",
    "    Handles formats like:\n",
    "    - 2024-01-15 14:30:00\n",
    "    - 01/15/2024 2:30 PM\n",
    "    - 2024-01-15T14:30:00\n",
    "    - and more\n",
    "    \"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    \n",
    "    # List of common date formats\n",
    "    formats = [\n",
    "        '%Y-%m-%d %H:%M:%S',\n",
    "        '%m/%d/%Y %I:%M %p',\n",
    "        '%m/%d/%Y %H:%M',\n",
    "        '%Y-%m-%dT%H:%M:%S',\n",
    "        '%Y-%m-%d',\n",
    "        '%m/%d/%Y',\n",
    "        '%d/%m/%Y %H:%M:%S',\n",
    "        '%d/%m/%Y %I:%M %p'\n",
    "    ]\n",
    "    \n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # If all formats fail, try pandas default parser\n",
    "    try:\n",
    "        return pd.to_datetime(date_str)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "print(\"✓ Date parser function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Visits Dataset\n",
    "print(\"Cleaning Visits dataset...\")\n",
    "\n",
    "# Parse all timestamp columns\n",
    "timestamp_cols = ['Arrival_Time', 'Registration_Time', 'Triage_Start', 'Triage_End', \n",
    "                  'Doctor_Assigned_Time', 'Treatment_Start', 'Departure_Time']\n",
    "\n",
    "for col in timestamp_cols:\n",
    "    if col in visits_df.columns:\n",
    "        visits_df[col] = visits_df[col].apply(parse_flexible_date)\n",
    "\n",
    "# Standardize triage levels\n",
    "if 'Triage_Level' in visits_df.columns:\n",
    "    visits_df['Triage_Level'] = visits_df['Triage_Level'].str.strip().str.upper()\n",
    "\n",
    "# Standardize shift\n",
    "if 'Shift' in visits_df.columns:\n",
    "    visits_df['Shift'] = visits_df['Shift'].str.strip().str.title()\n",
    "\n",
    "# Filter for East ER only\n",
    "if 'Hospital_ID' in visits_df.columns:\n",
    "    visits_df = visits_df[visits_df['Hospital_ID'] == 'MC_ER_EAST'].copy()\n",
    "\n",
    "print(f\"✓ Visits dataset cleaned: {len(visits_df):,} East ER records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Outcomes Dataset\n",
    "print(\"Cleaning Outcomes dataset...\")\n",
    "\n",
    "# Standardize disposition\n",
    "if 'Disposition' in outcomes_df.columns:\n",
    "    outcomes_df['Disposition'] = outcomes_df['Disposition'].str.strip().str.title()\n",
    "\n",
    "# Filter for East ER\n",
    "if 'Hospital_ID' in outcomes_df.columns:\n",
    "    outcomes_df = outcomes_df[outcomes_df['Hospital_ID'] == 'MC_ER_EAST'].copy()\n",
    "\n",
    "print(f\"✓ Outcomes dataset cleaned: {len(outcomes_df):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Patients Dataset\n",
    "print(\"Cleaning Patients dataset...\")\n",
    "\n",
    "# No specific cleaning needed for patients, but verify structure\n",
    "print(f\"✓ Patients dataset verified: {len(patients_df):,} records\")\n",
    "\n",
    "# Clean Staffing Dataset\n",
    "print(\"Cleaning Staffing dataset...\")\n",
    "\n",
    "# Parse date column if exists\n",
    "if 'Date' in staffing_df.columns:\n",
    "    staffing_df['Date'] = staffing_df['Date'].apply(parse_flexible_date)\n",
    "\n",
    "# Standardize shift\n",
    "if 'Shift' in staffing_df.columns:\n",
    "    staffing_df['Shift'] = staffing_df['Shift'].str.strip().str.title()\n",
    "\n",
    "print(f\"✓ Staffing dataset cleaned: {len(staffing_df):,} records\")\n",
    "\n",
    "# Clean Facility Dataset\n",
    "print(\"Cleaning Facility dataset...\")\n",
    "print(f\"✓ Facility dataset verified: {len(facility_df):,} records\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ALL DATASETS CLEANED SUCCESSFULLY\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Creating calculated fields for analysis including wait times, temporal features, and staffing ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time intervals (in minutes)\n",
    "print(\"Calculating time intervals...\")\n",
    "\n",
    "# Wait to Registration\n",
    "visits_df['Wait_to_Registration'] = (\n",
    "    (visits_df['Registration_Time'] - visits_df['Arrival_Time']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Registration Duration\n",
    "visits_df['Registration_Duration'] = (\n",
    "    (visits_df['Triage_Start'] - visits_df['Registration_Time']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Wait to Triage\n",
    "visits_df['Wait_to_Triage'] = (\n",
    "    (visits_df['Triage_Start'] - visits_df['Arrival_Time']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Triage Duration\n",
    "visits_df['Triage_Duration'] = (\n",
    "    (visits_df['Triage_End'] - visits_df['Triage_Start']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Wait to Doctor\n",
    "visits_df['Wait_to_Doctor'] = (\n",
    "    (visits_df['Doctor_Assigned_Time'] - visits_df['Triage_End']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Treatment Duration\n",
    "visits_df['Treatment_Duration'] = (\n",
    "    (visits_df['Departure_Time'] - visits_df['Treatment_Start']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Total ER Time\n",
    "visits_df['Total_ER_Time'] = (\n",
    "    (visits_df['Departure_Time'] - visits_df['Arrival_Time']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Time to Doctor (from arrival)\n",
    "visits_df['Time_to_Doctor'] = (\n",
    "    (visits_df['Doctor_Assigned_Time'] - visits_df['Arrival_Time']).dt.total_seconds() / 60\n",
    ").fillna(0)\n",
    "\n",
    "# Create 15-minute target flag\n",
    "visits_df['Seen_Within_15min'] = (visits_df['Time_to_Doctor'] <= 15).astype(int)\n",
    "\n",
    "print(\"✓ Time intervals calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features\n",
    "print(\"Creating temporal features...\")\n",
    "\n",
    "visits_df['Date'] = visits_df['Arrival_Time'].dt.date\n",
    "visits_df['Hour'] = visits_df['Arrival_Time'].dt.hour\n",
    "visits_df['Day_of_Week'] = visits_df['Arrival_Time'].dt.day_name()\n",
    "visits_df['Is_Weekend'] = visits_df['Arrival_Time'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "# Assign shift by hour (if not already present)\n",
    "def assign_shift(hour):\n",
    "    if 7 <= hour < 15:\n",
    "        return 'Day'\n",
    "    elif 15 <= hour < 23:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "if 'Shift' not in visits_df.columns or visits_df['Shift'].isna().any():\n",
    "    visits_df['Shift'] = visits_df['Hour'].apply(assign_shift)\n",
    "\n",
    "print(\"✓ Temporal features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all datasets\n",
    "print(\"Merging datasets...\")\n",
    "\n",
    "# Start with visits as the base\n",
    "merged_df = visits_df.copy()\n",
    "\n",
    "# Merge with patients\n",
    "if 'Patient_ID' in merged_df.columns and 'Patient_ID' in patients_df.columns:\n",
    "    merged_df = merged_df.merge(patients_df, on='Patient_ID', how='left', suffixes=('', '_patient'))\n",
    "    print(f\"  ✓ Merged with patients: {len(merged_df):,} records\")\n",
    "\n",
    "# Merge with outcomes\n",
    "if 'Visit_ID' in merged_df.columns and 'Visit_ID' in outcomes_df.columns:\n",
    "    merged_df = merged_df.merge(outcomes_df, on='Visit_ID', how='left', suffixes=('', '_outcome'))\n",
    "    print(f\"  ✓ Merged with outcomes: {len(merged_df):,} records\")\n",
    "\n",
    "# Merge with staffing (by Date and Shift)\n",
    "if 'Date' in merged_df.columns and 'Shift' in merged_df.columns:\n",
    "    # Ensure Date columns are same type\n",
    "    staffing_df['Date'] = pd.to_datetime(staffing_df['Date']).dt.date\n",
    "    merged_df = merged_df.merge(\n",
    "        staffing_df[['Date', 'Shift', 'Doctors_on_Duty', 'Nurses_on_Duty', 'Fast_Track_Open']], \n",
    "        on=['Date', 'Shift'], \n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"  ✓ Merged with staffing: {len(merged_df):,} records\")\n",
    "\n",
    "print(\"\\n✓ All datasets merged successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate staffing ratios\n",
    "print(\"Calculating staffing ratios...\")\n",
    "\n",
    "# Count patients per shift/date\n",
    "if 'Date' in merged_df.columns and 'Shift' in merged_df.columns:\n",
    "    shift_counts = merged_df.groupby(['Date', 'Shift']).size().reset_index(name='Patients_Count')\n",
    "    merged_df = merged_df.merge(shift_counts, on=['Date', 'Shift'], how='left')\n",
    "    \n",
    "    # Calculate ratios\n",
    "    if 'Nurses_on_Duty' in merged_df.columns:\n",
    "        merged_df['Patients_per_Nurse'] = (\n",
    "            merged_df['Patients_Count'] / merged_df['Nurses_on_Duty']\n",
    "        ).fillna(0)\n",
    "    \n",
    "    if 'Doctors_on_Duty' in merged_df.columns:\n",
    "        merged_df['Patients_per_Doctor'] = (\n",
    "            merged_df['Patients_Count'] / merged_df['Doctors_on_Duty']\n",
    "        ).fillna(0)\n",
    "\n",
    "print(\"✓ Staffing ratios calculated\")\n",
    "\n",
    "# Display merged dataset summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MERGED DATASET SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total records: {len(merged_df):,}\")\n",
    "print(f\"Total columns: {len(merged_df.columns)}\")\n",
    "print(f\"\\nKey Statistics:\")\n",
    "print(merged_df[['Time_to_Doctor', 'Total_ER_Time', 'Seen_Within_15min']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Comprehensive visual analysis of ER efficiency metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Wait Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait Time Breakdown by Stage\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "wait_stages = {\n",
    "    'Wait to\\nRegistration': merged_df['Wait_to_Registration'].mean(),\n",
    "    'Registration\\nDuration': merged_df['Registration_Duration'].mean(),\n",
    "    'Wait to\\nTriage': merged_df['Wait_to_Triage'].mean() - merged_df['Wait_to_Registration'].mean() - merged_df['Registration_Duration'].mean(),\n",
    "    'Triage\\nDuration': merged_df['Triage_Duration'].mean(),\n",
    "    'Wait to\\nDoctor': merged_df['Wait_to_Doctor'].mean(),\n",
    "    'Treatment\\nDuration': merged_df['Treatment_Duration'].mean()\n",
    "}\n",
    "\n",
    "# Filter out negative or invalid values\n",
    "wait_stages = {k: max(0, v) for k, v in wait_stages.items()}\n",
    "\n",
    "colors = ['#ff6b6b' if 'Wait' in k else '#4ecdc4' for k in wait_stages.keys()]\n",
    "bars = ax.bar(wait_stages.keys(), wait_stages.values(), color=colors, alpha=0.8, edgecolor='black')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f} min',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Average Time (minutes)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ER Wait Time Breakdown by Stage\\n(Red = Wait Time, Teal = Processing Time)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/wait_time_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Wait time breakdown chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-to-Doctor Distribution with 15-min threshold\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Filter extreme outliers for better visualization\n",
    "time_to_doctor_filtered = merged_df[merged_df['Time_to_Doctor'] < 300]['Time_to_Doctor']\n",
    "\n",
    "ax.hist(time_to_doctor_filtered, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(x=15, color='red', linestyle='--', linewidth=2, label='15-minute Target')\n",
    "\n",
    "# Calculate percentage meeting target\n",
    "pct_within_15 = (merged_df['Seen_Within_15min'].sum() / len(merged_df)) * 100\n",
    "ax.text(15, ax.get_ylim()[1] * 0.9, f'{pct_within_15:.1f}% within 15 min', \n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "        fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Time to Doctor (minutes)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Patients', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Distribution of Time-to-Doctor (with 15-Minute Target)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/time_to_doctor_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Time-to-doctor distribution saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total ER Time Distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Convert to hours and filter outliers\n",
    "total_er_hours = merged_df['Total_ER_Time'] / 60\n",
    "total_er_hours_filtered = total_er_hours[total_er_hours < 12]\n",
    "\n",
    "ax.hist(total_er_hours_filtered, bins=50, color='darkgreen', alpha=0.7, edgecolor='black')\n",
    "\n",
    "mean_hours = total_er_hours.mean()\n",
    "ax.axvline(x=mean_hours, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {mean_hours:.1f} hours')\n",
    "\n",
    "ax.set_xlabel('Total ER Time (hours)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Patients', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Distribution of Total ER Visit Duration', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/total_er_time_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Total ER time distribution saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal patterns figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Triage Level Performance\n",
    "if 'Triage_Level' in merged_df.columns:\n",
    "    triage_performance = merged_df.groupby('Triage_Level').agg({\n",
    "        'Seen_Within_15min': 'mean',\n",
    "        'Visit_ID': 'count'\n",
    "    }).reset_index()\n",
    "    triage_performance.columns = ['Triage_Level', 'Pct_Within_15min', 'Count']\n",
    "    triage_performance = triage_performance.sort_values('Triage_Level')\n",
    "    \n",
    "    bars = axes[0, 0].bar(triage_performance['Triage_Level'], \n",
    "                          triage_performance['Pct_Within_15min'] * 100,\n",
    "                          color='coral', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.1f}%',\n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[0, 0].set_ylabel('% Seen Within 15 Minutes', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Triage Level', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('Triage Level Performance', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "    axes[0, 0].set_ylim(0, 100)\n",
    "\n",
    "# 2. Patient Arrivals by Hour\n",
    "hourly_arrivals = merged_df['Hour'].value_counts().sort_index()\n",
    "axes[0, 1].plot(hourly_arrivals.index, hourly_arrivals.values, \n",
    "                marker='o', linewidth=2, markersize=8, color='darkblue')\n",
    "axes[0, 1].fill_between(hourly_arrivals.index, hourly_arrivals.values, alpha=0.3)\n",
    "axes[0, 1].set_ylabel('Number of Arrivals', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Hour of Day', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Patient Arrivals by Hour', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "axes[0, 1].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# 3. Average Time-to-Doctor by Shift\n",
    "shift_avg = merged_df.groupby('Shift')['Time_to_Doctor'].mean().sort_values(ascending=False)\n",
    "colors_shift = ['#ff6b6b' if x > shift_avg.mean() else '#51cf66' for x in shift_avg.values]\n",
    "bars = axes[1, 0].barh(shift_avg.index, shift_avg.values, color=colors_shift, \n",
    "                       alpha=0.8, edgecolor='black')\n",
    "\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    axes[1, 0].text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                    f'{width:.1f} min',\n",
    "                    ha='left', va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "axes[1, 0].set_xlabel('Average Time to Doctor (minutes)', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('Average Time-to-Doctor by Shift', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Average Time-to-Doctor by Day of Week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_avg = merged_df.groupby('Day_of_Week')['Time_to_Doctor'].mean()\n",
    "day_avg = day_avg.reindex(day_order)\n",
    "\n",
    "colors_day = ['#ff6b6b' if x > day_avg.mean() else '#51cf66' for x in day_avg.values]\n",
    "bars = axes[1, 1].bar(range(len(day_avg)), day_avg.values, color=colors_day, \n",
    "                      alpha=0.8, edgecolor='black')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.0f}',\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "axes[1, 1].set_xticks(range(len(day_avg)))\n",
    "axes[1, 1].set_xticklabels([d[:3] for d in day_avg.index], rotation=45)\n",
    "axes[1, 1].set_ylabel('Average Time to Doctor (minutes)', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Average Time-to-Doctor by Day of Week', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Temporal Patterns Analysis', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/temporal_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Temporal patterns analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Staffing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staffing Impact Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Patients per Nurse vs Wait Time\n",
    "if 'Patients_per_Nurse' in merged_df.columns:\n",
    "    # Create bins for patients per nurse\n",
    "    merged_df['Nurse_Ratio_Bin'] = pd.cut(merged_df['Patients_per_Nurse'], \n",
    "                                           bins=[0, 5, 10, 15, 20, 100],\n",
    "                                           labels=['0-5', '5-10', '10-15', '15-20', '20+'])\n",
    "    \n",
    "    nurse_impact = merged_df.groupby('Nurse_Ratio_Bin')['Time_to_Doctor'].mean()\n",
    "    \n",
    "    axes[0].plot(range(len(nurse_impact)), nurse_impact.values, \n",
    "                marker='o', linewidth=3, markersize=10, color='purple')\n",
    "    axes[0].set_xticks(range(len(nurse_impact)))\n",
    "    axes[0].set_xticklabels(nurse_impact.index)\n",
    "    axes[0].set_ylabel('Average Time to Doctor (minutes)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Patients per Nurse', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Impact of Nurse Staffing on Wait Times', fontsize=13, fontweight='bold')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Patients per Doctor vs Wait Time\n",
    "if 'Patients_per_Doctor' in merged_df.columns:\n",
    "    # Create bins for patients per doctor\n",
    "    merged_df['Doctor_Ratio_Bin'] = pd.cut(merged_df['Patients_per_Doctor'], \n",
    "                                            bins=[0, 10, 20, 30, 40, 200],\n",
    "                                            labels=['0-10', '10-20', '20-30', '30-40', '40+'])\n",
    "    \n",
    "    doctor_impact = merged_df.groupby('Doctor_Ratio_Bin')['Time_to_Doctor'].mean()\n",
    "    \n",
    "    axes[1].plot(range(len(doctor_impact)), doctor_impact.values, \n",
    "                marker='s', linewidth=3, markersize=10, color='orangered')\n",
    "    axes[1].set_xticks(range(len(doctor_impact)))\n",
    "    axes[1].set_xticklabels(doctor_impact.index)\n",
    "    axes[1].set_ylabel('Average Time to Doctor (minutes)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Patients per Doctor', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Impact of Doctor Staffing on Wait Times', fontsize=13, fontweight='bold')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Staffing Impact Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/staffing_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Staffing analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Demographics and Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics and Outcomes Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Satisfaction vs Wait Time\n",
    "if 'Patient_Satisfaction' in merged_df.columns:\n",
    "    satisfaction_wait = merged_df.groupby('Patient_Satisfaction')['Time_to_Doctor'].mean().sort_index()\n",
    "    \n",
    "    colors_sat = plt.cm.RdYlGn(np.linspace(0, 1, len(satisfaction_wait)))\n",
    "    bars = axes[0, 0].bar(satisfaction_wait.index.astype(str), satisfaction_wait.values, \n",
    "                          color=colors_sat, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.1f}',\n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[0, 0].set_xlabel('Patient Satisfaction Score', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Average Time to Doctor (minutes)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('Patient Satisfaction vs Wait Time', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Satisfaction by Age Group\n",
    "if 'Age' in merged_df.columns and 'Patient_Satisfaction' in merged_df.columns:\n",
    "    merged_df['Age_Group'] = pd.cut(merged_df['Age'], \n",
    "                                     bins=[0, 18, 35, 50, 65, 100],\n",
    "                                     labels=['0-18', '19-35', '36-50', '51-65', '65+'])\n",
    "    \n",
    "    age_satisfaction = merged_df.groupby('Age_Group')['Patient_Satisfaction'].mean()\n",
    "    \n",
    "    bars = axes[0, 1].bar(age_satisfaction.index.astype(str), age_satisfaction.values, \n",
    "                          color='skyblue', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.2f}',\n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[0, 1].set_xlabel('Age Group', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Average Satisfaction Score', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_title('Average Satisfaction by Age Group', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "    axes[0, 1].set_ylim(0, 5)\n",
    "\n",
    "# 3. Disposition Distribution (Pie Chart)\n",
    "if 'Disposition' in merged_df.columns:\n",
    "    disposition_counts = merged_df['Disposition'].value_counts()\n",
    "    \n",
    "    colors_pie = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854']\n",
    "    wedges, texts, autotexts = axes[1, 0].pie(disposition_counts.values, \n",
    "                                               labels=disposition_counts.index,\n",
    "                                               autopct='%1.1f%%',\n",
    "                                               colors=colors_pie[:len(disposition_counts)],\n",
    "                                               startangle=90)\n",
    "    \n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "        autotext.set_fontsize(10)\n",
    "    \n",
    "    axes[1, 0].set_title('Patient Disposition Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 4. Wait Time by Disposition\n",
    "if 'Disposition' in merged_df.columns:\n",
    "    disposition_wait = merged_df.groupby('Disposition')['Time_to_Doctor'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    bars = axes[1, 1].barh(disposition_wait.index, disposition_wait.values, \n",
    "                           color='lightcoral', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        axes[1, 1].text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                        f'{width:.1f} min',\n",
    "                        ha='left', va='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    axes[1, 1].set_xlabel('Average Time to Doctor (minutes)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_title('Average Wait Time by Disposition', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Demographics and Outcomes Analysis', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/demographics_outcomes.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Demographics and outcomes analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "numeric_cols = merged_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Select key features for correlation\n",
    "key_features = ['Time_to_Doctor', 'Total_ER_Time', 'Wait_to_Doctor', 'Treatment_Duration',\n",
    "                'Triage_Duration', 'Patients_per_Nurse', 'Patients_per_Doctor', \n",
    "                'Patient_Satisfaction', 'Age', 'Is_Weekend', 'Hour']\n",
    "\n",
    "# Filter to only existing columns\n",
    "key_features = [col for col in key_features if col in numeric_cols]\n",
    "\n",
    "correlation_matrix = merged_df[key_features].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "            vmin=-1, vmax=1, ax=ax)\n",
    "\n",
    "ax.set_title('Correlation Matrix of Key ER Efficiency Metrics', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print top correlations with wait time\n",
    "print(\"\\nTop Correlations with Time_to_Doctor:\")\n",
    "print(\"=\" * 50)\n",
    "time_to_doctor_corr = correlation_matrix['Time_to_Doctor'].sort_values(ascending=False)\n",
    "print(time_to_doctor_corr[time_to_doctor_corr.index != 'Time_to_Doctor'].head(10))\n",
    "\n",
    "if 'Patient_Satisfaction' in correlation_matrix.columns:\n",
    "    print(\"\\nTop Correlations with Patient_Satisfaction:\")\n",
    "    print(\"=\" * 50)\n",
    "    satisfaction_corr = correlation_matrix['Patient_Satisfaction'].sort_values(ascending=False)\n",
    "    print(satisfaction_corr[satisfaction_corr.index != 'Patient_Satisfaction'].head(10))\n",
    "\n",
    "print(\"\\n✓ Correlation analysis saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
